{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             A   B   C   D\n",
      "2019-03-01   0   1   2   3\n",
      "2019-03-02   4   5   6   7\n",
      "2019-03-03   8   9  10  11\n",
      "2019-03-04  12  13  14  15\n",
      "2019-03-05  16  17  18  19\n",
      "2019-03-06  20  21  22  23\n",
      "------------------\n",
      "             A  B  C     D  E\n",
      "2019-03-01   0  1  1   3.0  1\n",
      "2019-03-02   4  5  1   7.0  2\n",
      "2019-03-03   8  0  1   NaN  3\n",
      "2019-03-04  12  0  1   NaN  4\n",
      "2019-03-05  16  0  1  19.0  5\n",
      "2019-03-06  20  0  1  23.0  6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dates = pd.date_range('20190301', periods=6)\n",
    "df = pd.DataFrame(np.arange(24).reshape(6, 4), index=dates, columns=['A', 'B', 'C', 'D'])\n",
    "print(df)\n",
    "print('------------------')\n",
    "df.iloc[2, 2] = 111  # 给第2行第2列的元素赋值\n",
    "df.loc['20190303', 'B'] = 232  # 给行索引为2019-03-03，列索引为B的元素赋值\n",
    "df.B[df.A > 4] = 0   #把A列大于4的元素同行的B列元素都改成0\n",
    "df.C = 1   # 把第C列全部变成1\n",
    "df.iloc[2, 3] = np.nan\n",
    "df.iloc[3, 3] = np.nan\n",
    "df['E'] = pd.Series([1, 2, 3, 4, 5, 6], index=pd.date_range('20190301',periods=6)) # 增加一列，因为每一列都是一个Series\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             A  B  C     D  E\n",
      "2019-03-01   0  1  1   3.0  1\n",
      "2019-03-02   4  5  1   7.0  2\n",
      "2019-03-05  16  0  1  19.0  5\n",
      "2019-03-06  20  0  1  23.0  6\n",
      "             A  B  C  E\n",
      "2019-03-01   0  1  1  1\n",
      "2019-03-02   4  5  1  2\n",
      "2019-03-03   8  0  1  3\n",
      "2019-03-04  12  0  1  4\n",
      "2019-03-05  16  0  1  5\n",
      "2019-03-06  20  0  1  6\n",
      "             A  B  C     D  E\n",
      "2019-03-01   0  1  1   3.0  1\n",
      "2019-03-02   4  5  1   7.0  2\n",
      "2019-03-03   8  0  1   NaN  3\n",
      "2019-03-04  12  0  1   NaN  4\n",
      "2019-03-05  16  0  1  19.0  5\n",
      "2019-03-06  20  0  1  23.0  6\n"
     ]
    }
   ],
   "source": [
    "# pandas丢弃不完整数据，元素值为NAN\n",
    "print(df.dropna()) # 默认丢掉存在nan元素的行，可以使用axis参数来丢掉列，可选参数how，有‘any’和'all'两个参数\n",
    "print(df.dropna(axis=1))\n",
    "print(df.dropna(axis=0, how='all')) # any表示只要有一个就丢弃，all表示全部都是nan才丢弃"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             A  B  C     D  E\n",
      "2019-03-01   0  1  1   3.0  1\n",
      "2019-03-02   4  5  1   7.0  2\n",
      "2019-03-03   8  0  1   0.0  3\n",
      "2019-03-04  12  0  1   0.0  4\n",
      "2019-03-05  16  0  1  19.0  5\n",
      "2019-03-06  20  0  1  23.0  6\n"
     ]
    }
   ],
   "source": [
    "# pnadas填充不完整的数据,参数value表示要填充的数据\n",
    "print(df.fillna(value=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                A      B      C      D      E\n",
      "2019-03-01  False  False  False  False  False\n",
      "2019-03-02  False  False  False  False  False\n",
      "2019-03-03  False  False  False   True  False\n",
      "2019-03-04  False  False  False   True  False\n",
      "2019-03-05  False  False  False  False  False\n",
      "2019-03-06  False  False  False  False  False\n",
      "----------------------\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# pandas检查数据是否缺失, False表示无，True表示有\n",
    "print(df.isnull())\n",
    "print(\"----------------------\")\n",
    "print(np.any(df.isnull()) == True) # 如果数据表格太大，可以使用这个方法，只要有一个为True，就会返回True，否则返回False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas 读取csv文件\n",
    "data = pd.read_csv('F:\\machine_learing\\california_housing_train.csv')\n",
    "# 将数据转成成pickle文件\n",
    "data.to_pickle(\"test.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     a    b    c    d\n",
      "0  0.0  0.0  0.0  0.0\n",
      "1  0.0  0.0  0.0  0.0\n",
      "2  0.0  0.0  0.0  0.0\n",
      "0  1.0  1.0  1.0  1.0\n",
      "1  1.0  1.0  1.0  1.0\n",
      "2  1.0  1.0  1.0  1.0\n",
      "0  2.0  2.0  2.0  2.0\n",
      "1  2.0  2.0  2.0  2.0\n",
      "2  2.0  2.0  2.0  2.0\n",
      "-----------------------\n",
      "     a    b    c    d\n",
      "0  0.0  0.0  0.0  0.0\n",
      "1  0.0  0.0  0.0  0.0\n",
      "2  0.0  0.0  0.0  0.0\n",
      "3  1.0  1.0  1.0  1.0\n",
      "4  1.0  1.0  1.0  1.0\n",
      "5  1.0  1.0  1.0  1.0\n",
      "6  2.0  2.0  2.0  2.0\n",
      "7  2.0  2.0  2.0  2.0\n",
      "8  2.0  2.0  2.0  2.0\n"
     ]
    }
   ],
   "source": [
    "#  合并多个DataFrame， concat（concatenating）函数\n",
    "df1 = pd.DataFrame(np.ones((3, 4)) * 0, columns=['a', 'b', 'c', 'd'])\n",
    "df2 = pd.DataFrame(np.ones((3, 4)) * 1, columns=['a', 'b', 'c', 'd'])\n",
    "df3 = pd.DataFrame(np.ones((3, 4)) * 2, columns=['a', 'b', 'c', 'd'])\n",
    "res = pd.concat([df1, df2, df3],axis=0)  # 合并多个DataFrame，axis=0表示垂直合并，axis=1表示水平合并，默认为0\n",
    "print(res)\n",
    "# 我们如果要让index连续，则可以使用ignore_index参数，为True表示忽略索引，从0开始计算\n",
    "res = pd.concat([df1, df2, df3],axis=0, ignore_index=True)\n",
    "print('-----------------------')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     a    b    c    d    e\n",
      "1  0.0  0.0  0.0  0.0  NaN\n",
      "2  0.0  0.0  0.0  0.0  NaN\n",
      "3  0.0  0.0  0.0  0.0  NaN\n",
      "2  NaN  1.0  1.0  1.0  1.0\n",
      "3  NaN  1.0  1.0  1.0  1.0\n",
      "4  NaN  1.0  1.0  1.0  1.0\n",
      "     b    c    d\n",
      "1  0.0  0.0  0.0\n",
      "2  0.0  0.0  0.0\n",
      "3  0.0  0.0  0.0\n",
      "2  1.0  1.0  1.0\n",
      "3  1.0  1.0  1.0\n",
      "4  1.0  1.0  1.0\n"
     ]
    }
   ],
   "source": [
    "# pandas concat函数的join参数\n",
    "df1 = pd.DataFrame(np.ones((3, 4)) * 0, index=[1, 2, 3], columns=['a', 'b', 'c', 'd'])\n",
    "df2 = pd.DataFrame(np.ones((3, 4)) * 1, index=[2, 3, 4], columns=['b', 'c', 'd', 'e'])\n",
    "print(pd.concat([df1, df2], join='outer'))  # join参数默认是outer，会把不存在的那些值用NAN填充，比如df1没有e这一列，则用NAN填充这一列\n",
    "print(pd.concat([df1, df2], join='inner'))  # inner参数会合并所以数据存在的索引，如果不存在则会舍弃，例如df1和df2公共列为b,c,d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     a    b    c    d    b    c    d    e\n",
      "1  0.0  0.0  0.0  0.0  NaN  NaN  NaN  NaN\n",
      "2  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0\n",
      "3  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0\n",
      "---------------------\n",
      "     a    b    c    d\n",
      "1  0.0  0.0  0.0  0.0\n",
      "2  0.0  0.0  0.0  0.0\n",
      "3  0.0  0.0  0.0  0.0\n",
      "2  NaN  1.0  1.0  1.0\n",
      "3  NaN  1.0  1.0  1.0\n",
      "4  NaN  1.0  1.0  1.0\n"
     ]
    }
   ],
   "source": [
    "# conat函数的join_axes参数,\n",
    "print(pd.concat([df1, df2], axis=1,join_axes=[df1.index])) #表示按照df1的index水平合并，如果df2没有df1的index，则用NAN填充\n",
    "print('---------------------')\n",
    "print(pd.concat([df1, df2], axis=0,join_axes=[df1.columns])) # 表示按照df2的columns垂直合并，如果df2没有df1的columns则用NAN填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     a    b    c    d\n",
      "0  0.0  0.0  0.0  0.0\n",
      "1  0.0  0.0  0.0  0.0\n",
      "2  0.0  0.0  0.0  0.0\n",
      "3  1.0  1.0  1.0  1.0\n",
      "4  1.0  1.0  1.0  1.0\n",
      "5  1.0  1.0  1.0  1.0\n",
      "-------------------\n",
      "     a    b    c    d\n",
      "0  0.0  0.0  0.0  0.0\n",
      "1  0.0  0.0  0.0  0.0\n",
      "2  0.0  0.0  0.0  0.0\n",
      "3  1.0  1.0  1.0  1.0\n",
      "4  1.0  1.0  1.0  1.0\n",
      "5  1.0  1.0  1.0  1.0\n",
      "6  2.0  2.0  2.0  2.0\n",
      "7  2.0  2.0  2.0  2.0\n",
      "8  2.0  2.0  2.0  2.0\n"
     ]
    }
   ],
   "source": [
    "# pandas的append方法\n",
    "df1 = pd.DataFrame(np.ones((3, 4)) * 0, columns=['a', 'b', 'c', 'd'])\n",
    "df2 = pd.DataFrame(np.ones((3, 4)) * 1, columns=['a', 'b', 'c', 'd'])\n",
    "df3 = pd.DataFrame(np.ones((3, 4)) * 2, columns=['a', 'b', 'c', 'd'])\n",
    "print(df1.append(df2, ignore_index=True))  # 一个参数df2\n",
    "print('-------------------')\n",
    "print(df1.append([df2, df3], ignore_index=True)) # 使用列表可以使用多个参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     a    b    c    d\n",
      "0  0.0  0.0  0.0  0.0\n",
      "1  0.0  0.0  0.0  0.0\n",
      "2  0.0  0.0  0.0  0.0\n",
      "3  1.0  2.0  3.0  4.0\n",
      "----------------------\n",
      "     a    b    c    d\n",
      "0  0.0  0.0  0.0  0.0\n",
      "1  0.0  0.0  0.0  0.0\n",
      "2  0.0  0.0  0.0  0.0\n",
      "3  1.0  2.0  3.0  4.0\n"
     ]
    }
   ],
   "source": [
    "# pandas append方法添加Series\n",
    "s = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])\n",
    "print(df1.append(s, ignore_index=True))  # 如果不使用ignore_index参数，则会报错，因为Series没有指定index名\n",
    "print('----------------------')\n",
    "\n",
    "# 还可以在Series定义时增加一个name属性\n",
    "s1 = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'], name = 3)\n",
    "print(df1.append(s1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
